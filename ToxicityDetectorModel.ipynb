{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNP7UDoCywMHF8TJPbXVNyr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn\n",
        "\n",
        "!pip list"
      ],
      "metadata": {
        "id": "89ZohcmFyVyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "VDb24f7FyYwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding, Input"
      ],
      "metadata": {
        "id": "o9jBw--cybmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv(os.path.join('datasets','train.csv', 'train.csv'))\n",
        "df = pd.read_csv(r'/content/train.csv')\n",
        "\n",
        "df.head()\n",
        "\n",
        "X = df['comment_text']\n",
        "y = df[df.columns[2:]].values\n",
        "\n",
        "MAX_FETURES = 200000 # number of words in the vocab\n",
        "SEQUENCE_LENGTH = 1800"
      ],
      "metadata": {
        "id": "eX-ClQgmyetg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FETURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')\n",
        "\n",
        "vectorizer.adapt(X.values)\n",
        "\n",
        "vectorized_txt = vectorizer(X.values)\n",
        "\n",
        "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_txt, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps bottlenecks\n",
        "\n",
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EK8uVDP_ylmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(SEQUENCE_LENGTH,)))\n",
        "model.add(Embedding(input_dim=MAX_FETURES+1,  # +1 for padding token\n",
        "                   output_dim=32,\n",
        "                   input_length=SEQUENCE_LENGTH))\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(6, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "grVuPWRsysif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd77e5b-f978-46d9-9cbf-871cf8537c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "aWn9qrYIyuhF",
        "outputId": "6b0455ca-2558-4083-859a-56cd5e2a2584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1800\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │       \u001b[38;5;34m6,400,032\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400,032</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,491,686\u001b[0m (24.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,491,686</span> (24.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,491,686\u001b[0m (24.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,491,686</span> (24.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train, epochs=10, validation_data=val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjq6-B8tyx5F",
        "outputId": "9505c092-1045-4011-d066-2390f59a26dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 107ms/step - loss: 0.0840 - val_loss: 0.0445\n",
            "Epoch 2/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 107ms/step - loss: 0.0467 - val_loss: 0.0405\n",
            "Epoch 3/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 106ms/step - loss: 0.0420 - val_loss: 0.0368\n",
            "Epoch 4/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 107ms/step - loss: 0.0381 - val_loss: 0.0354\n",
            "Epoch 5/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 106ms/step - loss: 0.0352 - val_loss: 0.0310\n",
            "Epoch 6/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 105ms/step - loss: 0.0321 - val_loss: 0.0282\n",
            "Epoch 7/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 105ms/step - loss: 0.0289 - val_loss: 0.0277\n",
            "Epoch 8/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 105ms/step - loss: 0.0273 - val_loss: 0.0238\n",
            "Epoch 9/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 104ms/step - loss: 0.0252 - val_loss: 0.0211\n",
            "Epoch 10/10\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 111ms/step - loss: 0.0230 - val_loss: 0.0204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize and reshape single text input\n",
        "input_text = vectorizer('You freaking suck! I am going to hit you.')\n",
        "input_text = tf.expand_dims(input_text, 0)  # Add batch dimension\n",
        "\n",
        "# Make prediction\n",
        "res = model.predict(input_text)\n",
        "print(\"Prediction probabilities:\", res)\n",
        "print(\"Binary predictions:\", (res > 0.5).astype(int))\n",
        "\n",
        "# Shape of the result\n",
        "print(\"Result shape:\", res.shape)\n",
        "\n",
        "# Test batch prediction\n",
        "batch_X, batch_y = test.as_numpy_iterator().next()\n",
        "batch_predictions = model.predict(batch_X)\n",
        "print(\"\\nBatch predictions (binary):\", (batch_predictions > 0.5).astype(int))\n",
        "print(\"Batch predictions shape:\", batch_predictions.shape)\n",
        "\n",
        "# Optional: Print the toxicity categories alongside predictions\n",
        "categories = df.columns[2:]  # Get the toxicity category names\n",
        "for i, category in enumerate(categories):\n",
        "    print(f\"{category}: {res[0][i]:.4f} -> {int(res[0][i] > 0.5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XioiVVh2RANF",
        "outputId": "36422d65-920a-49bf-cc59-b549a7a0a08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
            "Prediction probabilities: [[0.9980788  0.06591689 0.9807509  0.0068792  0.9053064  0.00975615]]\n",
            "Binary predictions: [[1 0 1 0 1 0]]\n",
            "Result shape: (1, 6)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "\n",
            "Batch predictions (binary): [[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n",
            "Batch predictions shape: (16, 6)\n",
            "toxic: 0.9981 -> 1\n",
            "severe_toxic: 0.0659 -> 0\n",
            "obscene: 0.9808 -> 1\n",
            "threat: 0.0069 -> 0\n",
            "insult: 0.9053 -> 1\n",
            "identity_hate: 0.0098 -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
      ],
      "metadata": {
        "id": "hSufVINwzYKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    # Unpack the batch\n",
        "    X_true, y_true = batch\n",
        "    # Make a prediction\n",
        "    yhat = model.predict(X_true)\n",
        "\n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "\n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)\n",
        "\n",
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "YnKQvhPDzWF_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio jinja2"
      ],
      "metadata": {
        "id": "eqxUzJ1HzdDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "heWDvkkhzi_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('toxicityModel.h5')\n",
        "\n",
        "model = tf.keras.models.load_model('toxicityModel.h5')\n",
        "\n",
        "input_str = vectorizer('hey i freaken hate you!')\n",
        "\n",
        "res = model.predict(np.expand_dims(input_str,0))\n",
        "\n",
        "res"
      ],
      "metadata": {
        "id": "LxuJzL7hzqfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c630109-2355-49d9-efc6-6fa3a0a5c29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.89187646, 0.00154522, 0.0268265 , 0.01062214, 0.14537996,\n",
              "        0.01921617]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def score_comment(comment):\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "\n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "    return text\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=score_comment,\n",
        "    inputs=gr.Textbox(lines=2, placeholder='Comment to score'),\n",
        "    outputs=gr.Textbox(),\n",
        "    title=\"Toxicity Classifier\",\n",
        "    description=\"Enter a comment to check for different types of toxicity.\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "490BWwpyzsTX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "9f27a189-968c-4b5b-8103-b6095471167c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7782f35da6c63ab689.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7782f35da6c63ab689.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('model.pkl', 'wb') as f:\n",
        "  pickle.dump(model,f)"
      ],
      "metadata": {
        "id": "DAYTj9b0TiNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hjCyp5LvIBWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}